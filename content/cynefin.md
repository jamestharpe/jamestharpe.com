---
date: 2021-06-26T15:01:25-04:00
description: "A framework for making sense out of chaotic or complex situations"
tags: [ "change-management" ]
title: "Cynefin Framework"
---

# Cynefin Framework

The **Cynefin Framework** is a [change management](change-management.md) framework to aid decision making, especially in chaotic or complex situations. The term "cynefin" (pronounced _kuh-nev-in_) means "habitat" in Welsh, and is intended to invoke a sense of interconnectedness that can never be fully understood.

[![Cynefin framework visualized by Edwin Stoop of Sketching Maniacs](/img/cynefin.jpg)](/img/cynefin.jpg)

## Cynefin Contexts

A **context**, sometimes called a **domain**, is the set of circumstances that drive decisions. Cynefin seeks to match actions to context to aid decision making. Each context is paired with a decision model for sensing, acting, analyzing, categorizing, and responding based on the available information.

### Disorder

Disorder is the center of the cynefin framework. When a system is in **disorder**, the specific context is unclear. When in disorder, the determination whether the context is chaos, complex, complicated, or obvious may be subjectively assessed based on each person's background or personal history rather than an objective criteria.

A system in disorder is one in which decisions are most likely to be wrong. Disorder differs from chaos in that a chaotic system lacks order, where as a disordered system _unknowingly_ falls under any of the other domains.

Bureaucrats tend to see problems through the _simple_ context, as failures of process. Experts tend to see problems through the _complicated_ context, as failure of analysis. The cynefin framework provides a means of parsing through multiple perspectives to assign the right context, think in the most effective terms, and subsequently take the right actions.

### Chaotic: Act, Sense, Respond

In **chaotic systems**, there is no definitive understanding between cause and effect. This can be intentional when existing rules are cast aside - usually in a controlled manner, such as a skunk-works project - in an attempt to innovate. Chaotic systems also emerge unintentionally, when existing systems fail or are disrupted.

The decision model for chaotic systems is:

1. **Act** by doing _something_, often something extreme, as a way to establish a baseline for improvement
2. **Sense** the situation created through action
3. **Respond** with "novel practices" to understand and improve upon the baseline

**Novel practices** are practices that seem to work or seem like they will work and may be discarded as quickly as they are adopted in attempts to stabilize the system.

Chaotic systems have no effective constraints. The lack of effective constraints can be an absence of constraints, or a set of constraints that must be broken for progress to be made.

### Complex: Probe, Sense, Respond

In **complex systems**, there is little understanding of the relationship between cause and effect, thus knowledge is gained largely through trial-and-error and progress requires exaptive practice (the re-use of existing tools and knowledge in new ways).

The decision model for complex systems is:

1. **Probe** the situation through small actions, targeted to safely increase understanding and make incremental progress
2. **Sense** the situation based on the facts established from probes
3. **Respond** to the situation with "emergent/exaptive practices" to achieve informative results

**Emergent/exaptive practices** consist of general guidance based on previous experience including heuristics, narratives, and historic "what worked for me" examples. This often includes existing tools, repurposed for novel applications.

Complex systems use **enabling constraints**, which provide lenses through which to view complexity, and guiding principles. Complex systems are best managed through the discovery and communication of enabling constraints. For example, the US Marines use "capture the high ground, stay in touch, and keep moving" as the enabling constraints for active battlefields.

###  Complicated: Sense, Analyze, Respond

In **complicated systems**, there is a direct and known relation between cause and effect, however that relationship is not self-evident unless you're an expert. Complicated systems differ from complex systems in that experts can be trusted in a complicated situation, but not in a complex one. The maintenance of complicated systems therefore requires the continual building of expertise and trust in them.

The decision model for obvious systems is:

1. **Sense** the situation by establishing the facts of what is known
2. **Analyze** the situation through employment of subject matter experts (SMEs)
3. **Respond** to the situation with "good practices" to achieve a probable result

**Good practices** provide a menu of sensible options based on hypotheses formed from context and analysis. Subsequent actions are then most effectively selected by those with the most knowledge of the context and expertise in the system. 

A common mistake in complicated systems is to impose best practices in a context where good practices are required. In complicated systems, best practices oversimplify the context, lead to suboptimal decisions, and may erode trust in expertise. When trust is sufficiently eroded, a complicated system can devolve into a complex one.

Complicated systems use **governing constraints**, which define the _limits_ of what _must_ or _must not_ be done and otherwise provide flexibility context-based decision making.

The border between complicated and complex 

### Obvious: Sense, Categorize, Respond

In **obvious systems** (formerly _simple_ systems), there is a direct and known relationship between cause and effect, which is clear to virtually everyone. Obvious systems are predictable, with clear actions and reactions, and hardly anyone would dispute how the system works.

The decision model for obvious systems is:

1. **Sense** the situation by establishing the facts of what is known
2. **Categorize** the situation according to the system into established categories
3. **Respond** to the situation with the prescribed "best practice" to achieve a predictable result

**Best practice** provide specific actions for well-categorized situations. Subsequent actions are then most effectively selected by the system its self in most cases.

Obvious systems use **rigid constrains**, sometimes called **fixed constraints**, which are constraints that require little context and tend to operate according to simple "if, then" rules, though perhaps not completely without exception.

The border between obvious and chaos is called the "zone of complacency" where if an obvious system is over-constrained - if the rules are too rigid - it may collapse and become a chaotic system.

## Video: The Cynefin Framework

<iframe width="560" height="315" src="https://www.youtube.com/embed/N7oz366X0-8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
